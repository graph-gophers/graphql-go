package graphql_test

import (
	"context"
	"strings"
	"testing"
	"time"

	"github.com/graph-gophers/graphql-go"
)

const simpleSchema = `
	schema {
		query: Query
	}

	type Query {
		a: String
	}
`

type simpleResolver struct{}

func (r *simpleResolver) A() *string {
	val := "value"
	return &val
}

// TestDDoSVulnerability_ManyFieldsAtSameLevel tests the vulnerability where
// a query with thousands of fields at the same level causes CPU overload.
// This test demonstrates the vulnerability and is skipped by default.
func TestDDoSVulnerability_ManyFieldsAtSameLevel(t *testing.T) {
	t.Skip("Skipping vulnerability demonstration test - it would timeout without the fix")
	// Create a query with many duplicate fields at the same level
	// This is the attack vector from the user's report
	numFields := 5000
	fields := make([]string, numFields)
	for i := 0; i < numFields; i++ {
		fields[i] = "a"
	}

	maliciousQuery := "query { " + strings.Join(fields, " ") + " }"

	schema := graphql.MustParseSchema(simpleSchema, &simpleResolver{})

	// Set a timeout to prevent the test from hanging indefinitely
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	// This should complete quickly, but without a fix it will cause CPU overload
	done := make(chan struct{})
	go func() {
		result := schema.Exec(ctx, maliciousQuery, "", nil)
		// We expect either:
		// 1. An error indicating the query is too complex (with fix)
		// 2. Success (but it should be fast)
		if result.Errors != nil {
			t.Logf("Query returned errors (expected with fix): %v", result.Errors)
		}
		close(done)
	}()

	select {
	case <-done:
		t.Log("Query completed")
	case <-ctx.Done():
		t.Fatal("Query timed out - DDoS vulnerability confirmed")
	}
}

// TestDDoSVulnerability_ExtremeCase tests an even more extreme case
// This test demonstrates the vulnerability and is skipped by default.
func TestDDoSVulnerability_ExtremeCase(t *testing.T) {
	t.Skip("Skipping extreme vulnerability demonstration test - it would timeout without the fix")
	// Create a query with an extreme number of fields (like the user's example)
	// The user's query had roughly 100,000+ fields
	numFields := 100000
	fields := make([]string, numFields)
	for i := 0; i < numFields; i++ {
		fields[i] = "a"
	}

	maliciousQuery := "query { " + strings.Join(fields, " ") + " }"

	schema := graphql.MustParseSchema(simpleSchema, &simpleResolver{})

	// Set a strict timeout
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	done := make(chan struct{})
	var testErr error
	go func() {
		start := time.Now()
		result := schema.Exec(ctx, maliciousQuery, "", nil)
		duration := time.Since(start)

		t.Logf("Query took %v to complete", duration)

		// With a fix, this should be rejected quickly (< 100ms)
		// Without a fix, this will timeout
		if duration > 1*time.Second {
			testErr = nil // Will be caught by timeout
		}

		if result.Errors != nil {
			t.Logf("Query returned errors: %v", result.Errors)
		}
		close(done)
	}()

	select {
	case <-done:
		if testErr != nil {
			t.Fatal(testErr)
		}
		t.Log("Query completed (should be fast with fix)")
	case <-ctx.Done():
		t.Fatal("Query timed out - DDoS vulnerability confirmed. This query with 100k fields should be rejected immediately.")
	}
}

// TestDDoSVulnerability_ValidationOnly tests that the validation phase itself is vulnerable
// This test demonstrates the vulnerability and is skipped by default.
func TestDDoSVulnerability_ValidationOnly(t *testing.T) {
	t.Skip("Skipping validation-only vulnerability demonstration test - it would timeout without the fix")
	// Test just the validation without execution
	numFields := 10000
	fields := make([]string, numFields)
	for i := 0; i < numFields; i++ {
		fields[i] = "a"
	}

	maliciousQuery := "query { " + strings.Join(fields, " ") + " }"

	schema := graphql.MustParseSchema(simpleSchema, &simpleResolver{})

	start := time.Now()
	errors := schema.Validate(maliciousQuery)
	duration := time.Since(start)

	t.Logf("Validation took %v", duration)
	t.Logf("Validation errors: %v", errors)

	// Without a fix, validation can take seconds for 10k fields
	// With a fix, it should be rejected immediately (< 100ms)
	if duration > 500*time.Millisecond {
		t.Errorf("Validation took too long (%v). This indicates a DDoS vulnerability in the validation phase.", duration)
	}
}

// TestDDoSVulnerability_WithFix tests that the fix prevents the attack
func TestDDoSVulnerability_WithFix(t *testing.T) {
	// Create a query with many fields
	numFields := 10000
	fields := make([]string, numFields)
	for i := 0; i < numFields; i++ {
		fields[i] = "a"
	}

	maliciousQuery := "query { " + strings.Join(fields, " ") + " }"

	// Create schema with MaxSelectionSetSize limit
	schema := graphql.MustParseSchema(simpleSchema, &simpleResolver{}, graphql.MaxSelectionSetSize(100))

	start := time.Now()
	errors := schema.Validate(maliciousQuery)
	duration := time.Since(start)

	t.Logf("Validation with fix took %v", duration)
	t.Logf("Validation errors: %v", errors)

	// With the fix, the query should be rejected immediately
	if len(errors) == 0 {
		t.Fatal("Expected validation errors, but got none")
	}

	found := false
	for _, err := range errors {
		if strings.Contains(err.Message, "invalid query") {
			found = true
			break
		}
	}
	if !found {
		t.Errorf("Expected error about exceeding max selection set size or repeated tokens, but got: %v", errors)
	}

	// Validation should be fast (< 100ms)
	if duration > 100*time.Millisecond {
		t.Errorf("Validation took too long (%v) even with the fix", duration)
	}
}

// TestDDoSVulnerability_FixWithReasonableQuery tests that the fix doesn't break reasonable queries
func TestDDoSVulnerability_FixWithReasonableQuery(t *testing.T) {
	// Create a reasonable query with just a few fields
	reasonableQuery := "query { a a a a a }"

	// Create schema with MaxSelectionSetSize limit
	schema := graphql.MustParseSchema(simpleSchema, &simpleResolver{}, graphql.MaxSelectionSetSize(100))

	errors := schema.Validate(reasonableQuery)

	t.Logf("Validation errors for reasonable query: %v", errors)

	// This should not be blocked
	if len(errors) > 0 {
		// Check if there's an error about max selection set size
		for _, err := range errors {
			if strings.Contains(err.Message, "exceeds the maximum allowed size") {
				t.Errorf("Reasonable query was incorrectly blocked by MaxSelectionSetSize")
			}
		}
	}
}

// TestDDoSVulnerability_RepeatedTokenDetection tests early detection of repeated field patterns
func TestDDoSVulnerability_RepeatedTokenDetection(t *testing.T) {
	// Create a query with 150 repeated "a" fields - should be rejected during parsing
	numFields := 150
	fields := make([]string, numFields)
	for i := 0; i < numFields; i++ {
		fields[i] = "a"
	}

	maliciousQuery := "query { " + strings.Join(fields, " ") + " }"

	schema := graphql.MustParseSchema(simpleSchema, &simpleResolver{})

	start := time.Now()
	result := schema.Exec(context.Background(), maliciousQuery, "", nil)
	duration := time.Since(start)

	t.Logf("Query with %d repeated tokens took %v", numFields, duration)
	t.Logf("Errors: %v", result.Errors)

	// Should have errors
	if len(result.Errors) == 0 {
		t.Fatal("Expected errors for repeated token attack, but got none")
	}

	// Should be rejected quickly (parsing phase)
	if duration > 100*time.Millisecond {
		t.Errorf("Query took too long (%v) - should be rejected during parsing", duration)
	}

	// Check error message mentions repetition or DDoS
	foundRelevantError := false
	for _, err := range result.Errors {
		if strings.Contains(err.Message, "syntax error: invalid query") {
			foundRelevantError = true
			t.Logf("Found expected error: %s", err.Message)
			break
		}
	}

	if !foundRelevantError {
		t.Errorf("Expected error about repeated tokens, got: %v", result.Errors)
	}
}

// TestDDoSVulnerability_RepeatedTokenAtThreshold tests behavior at the threshold
func TestDDoSVulnerability_RepeatedTokenAtThreshold(t *testing.T) {
	// Create a query with exactly 100 repeated "a" fields - should be allowed
	numFields := 100
	fields := make([]string, numFields)
	for i := 0; i < numFields; i++ {
		fields[i] = "a"
	}

	queryAtThreshold := "query { " + strings.Join(fields, " ") + " }"

	schema := graphql.MustParseSchema(simpleSchema, &simpleResolver{})

	start := time.Now()
	result := schema.Exec(context.Background(), queryAtThreshold, "", nil)
	duration := time.Since(start)

	t.Logf("Query with %d repeated tokens (at threshold) took %v", numFields, duration)
	t.Logf("Errors: %v", result.Errors)

	// Should be fast
	if duration > 100*time.Millisecond {
		t.Errorf("Query took too long (%v)", duration)
	}

	// Check that it doesn't error due to repetition (100 is the threshold, so should be allowed)
	for _, err := range result.Errors {
		if strings.Contains(err.Message, "repeated") ||
			strings.Contains(err.Message, "repetition") ||
			strings.Contains(err.Message, "DDoS") {
			t.Errorf("Query at threshold should not be blocked for repetition: %s", err.Message)
		}
	}
}

// TestDDoSVulnerability_NonRepeatedFields tests that different fields don't trigger detection
func TestDDoSVulnerability_NonRepeatedFields(t *testing.T) {
	// Create a query with many different fields - should not be blocked by repetition detection
	// Note: This will still be caught by MaxSelectionSetSize if configured
	queryWithDifferentFields := "query { a b c d e f g h i j k l m n o p q r s t u v w x y z }"

	schema := graphql.MustParseSchema(simpleSchema, &simpleResolver{})

	start := time.Now()
	result := schema.Exec(context.Background(), queryWithDifferentFields, "", nil)
	duration := time.Since(start)

	t.Logf("Query with different fields took %v", duration)
	t.Logf("Errors: %v", result.Errors)

	// Check that it doesn't error due to repetition
	for _, err := range result.Errors {
		if strings.Contains(err.Message, "repeated") ||
			strings.Contains(err.Message, "repetition") ||
			strings.Contains(err.Message, "DDoS") {
			t.Errorf("Different fields should not trigger repetition detection: %s", err.Message)
		}
	}
}
